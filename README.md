# VMWare Launch ML/AI
This is the course page for a 3-day intensive workshop for the ML/AI pillar of the VMWare Launch program and culminates in a hackathon.

# Objectives
After this course, students will be able to:

- Explain what machine learning is and how it works
- Write Python code for the purpose of data analysis or machine learning
- Use the Pandas library for data wrangling 
- Build supervised learning (predictive) models in scikit-learn
- Use basic techniques to "tune" the models for better performance
- Explain what reinforcement learning and neural networks are
- Execute the machine learning workflow start-to-finish

# Agenda
The workshop is broken down into three days of training

## Day 1: Basic Model Building
1. [30 min] Overview of Machine Learning (ML) ([slides](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%201/DI_Overview_of_ML.key))
2. [2 hrs] Practical Python for ML ([notebook](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%201/Practical%20Python%20for%20ML.ipynb))
3. [2 hrs] Practical Pandas for data wrangling([notebook](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%201/Practical%20Pandas%20for%20Data%20Wrangling.ipynb))
4. [1.5 hrs] Building machine learning models ([notebook](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%201/Building%20Models.ipynb))

## Day 2: Tuning, Neural Nets, RL & Hackathon
1. [1.5 hrs] Applying models and Neural Networks and Reinforcement Learning (RL) ([notebook](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%202/ML%20Practice%2C%20Neural%20Nets%2C%20and%20RL.ipynb))
2. [1 hr] Data Munging & Feature Engineering Practice ([notebook](https://github.com/suneel0101/ml-ai-vmware-launch/blob/master/Day%202/Data%20Munging%20Practice.ipynb))
3. Start Hackathon: Loan Default Prediction ([source](https://www.kaggle.com/c/home-credit-default-risk/overview))

## Day 3: Hackathon & Presentations
1. [3-4 hrs] Hack Time for Hackathon
2. [1 hr] Presentations and Discussion
3. [0.5 hrs] Review Key Takeaways
4. [0.5 hrs] Open Q & A


## Post-Class Work
### Articles
1. The Bias-Variance Tradeoff: Model errors are important to understand and fall into either bias or variance and often there is a tradeoff between the two: http://scott.fortmann-roe.com/docs/BiasVariance.html

2. A Practical Guide to Feature Engineering: One can make their models more performant by adding more data, enriching the features, or choosing better models. The bulk of the work is in the feature engineering https://heartbeat.fritz.ai/a-practical-guide-to-feature-engineering-in-python-8326e40747c8

3. The Curse of Dimensionality: An important consideration in adding more features to your dataset is understanding how that affects the density of your data and for certain models results in "lonely data" https://towardsdatascience.com/the-curse-of-dimensionality-minus-the-curse-of-jargon-520da109fc87

### Pluralsight Course
https://app.pluralsight.com/library/courses/google-machine-learning-apis-designing-implementing-solutions/table-of-contents

It is useful to leverage as much existing intelligence as possible, whether it is AWS, Google ML, or Azure. Google ML tooling in particular is very user friendly and well-developed.

### Exercise
See the iPython notebooks under Post-Class Work. One contains the exercises without solutions and the other contains the solutions.